# Written by Yassaanah
# Decision tree classifier for my thesis
# SQL injection Detection using machine Learning (Supervised ML)

import pandas as pd # dataframe for the analysis
import numpy as np # Scientific computing library-arrays
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.model_selection import train_test_split

from matplotlib import pyplot as plt
import seaborn as sb

import graphviz
import pydotplus
import io
import imageio
from scipy import misc

%matplotlib inline


SQL injection attacks Attributes EDA (Exploratory Data Analysis)
import the dataset
EDA to visualize the data and observe the structure
Train the classifier (Decision tree)
Predict the target query using the trained classifier



data = pd.read_csv('./data/sql_dataset.csv')
data.describe()
data.head()
data.info()

train, test = train_test_split(data, test_size = 0.2) # the test size is set to 20%

print ("Training Size: {}; Test Size: {}".format(len(train), len(test))) #print the number of training and test size

train.shape # this shows the number of rows and columns on data

# custom color
red_blue = ["#19B5FE", "#EF4836"]
palette = sb.color_palette(red_blue)
sb.set_palette(palette)
sb.set_style("white")


# if command is positive & malicious is 1, then query is malicious
# if command is negative & malicious is 0, then query is non-malicious

pos_command =data[data['Malicious']==1]['Command'] 
neg_command =data[data['Malicious']==0]['Command'] 
pos_Punctuations =data[data['Malicious']==1]['Punctuations'] 
neg_Punctuations =data[data['Malicious']==0]['Punctuations'] 

pos_Comparison =data[data['Malicious']==1]['Comparison'] 
neg_Comparison =data[data['Malicious']==0]['Comparison'] 

pos_Comments =data[data['Malicious']==1]['Comments']
neg_Comments =data[data['Malicious']==0]['Comments'] 

pos_Logical_Op =data[data['Malicious']==1]['Logical Operators']
neg_Logical_Op =data[data['Malicious']==0]['Logical Operators'] 

pos_Literal =data[data['Malicious']==1]['Literal'] 
neg_Literal =data[data['Malicious']==0]['Literal'] 

pos_identifier =data[data['Malicious']==1]['Identifier']
neg_identifier =data[data['Malicious']==0]['Identifier'] 

pos_Auxiliary =data[data['Malicious']==1]['Auxiliary'] 
neg_Auxiliary =data[data['Malicious']==0]['Auxiliary'] 

pos_Location =data[data['Malicious']==1]['Location'] 
neg_Location =data[data['Malicious']==0]['Location'] 


fig = plt.figure(figsize=(12, 8))
plt.title("Distributions of query based on the Command feature of the query") # the title of the 
pos_command.hist(alpha=0.7, bins =30, label = "Malicious")
neg_command.hist(alpha=0.7, bins =30, label = "Non-malicious") 
plt.legend(loc = "upper right") # puts the legend at the upper top right corner of the histogram


fig2 = plt.figure(figsize=(15, 15))

# Command
ax3 = fig2.add_subplot(331)
ax3.set_xlabel('Command')
ax3.set_ylabel('Count')
ax3.set_title('Command query Distribution')
pos_command.hist(alpha=0.5, bins=30)
#ax4 = fig2.add_subplot(331)
neg_command.hist(alpha=0.5, bins=30)


# Punctuations
ax4 = fig2.add_subplot(332)
ax4.set_xlabel('Punctuations')
ax4.set_ylabel('Count')
ax4.set_title('Punctuations query Distribution')
pos_Punctuations.hist(alpha=0.5, bins=30)
#ax5 = fig2.add_subplot(332)
neg_Punctuations.hist(alpha=0.5, bins=30)

# Comparison
ax6 = fig2.add_subplot(333)
ax6.set_xlabel('Comparison')
ax6.set_ylabel('Count')
ax6.set_title('Comparison query Distribution')
pos_Comparison.hist(alpha=0.5, bins=30)
#ax7 = fig2.add_subplot(333)
neg_Comparison.hist(alpha=0.5, bins=30)

# Comments
ax8 = fig2.add_subplot(334)
ax8.set_xlabel('Comments')
ax8.set_ylabel('Count')
ax8.set_title('Comments query Distribution')
pos_Comments.hist(alpha=0.5, bins=30)
#ax9 = fig2.add_subplot(334)
neg_Comments.hist(alpha=0.5, bins=30)

# Logical Operators
ax10 = fig2.add_subplot(335)
ax10.set_xlabel('Logical Operators')
ax10.set_ylabel('Count')
ax10.set_title('Logical Operators query Distribution')
pos_Logical_Op.hist(alpha=0.5, bins=30)
#ax11 = fig2.add_subplot(335)
neg_Logical_Op.hist(alpha=0.5, bins=30)

# Literals
ax12 = fig2.add_subplot(336)
ax12.set_xlabel('Literals')
ax12.set_ylabel('Count')
ax12.set_title('Literals query Distribution')
pos_Literal.hist(alpha=0.5, bins=30)
#ax13 = fig2.add_subplot(336)
neg_Literal.hist(alpha=0.5, bins=30)

# Identifier
ax14 = fig2.add_subplot(337)
ax14.set_xlabel('Identifier')
ax14.set_ylabel('Count')
ax14.set_title('Identifier query Distribution')
pos_identifier.hist(alpha=0.5, bins=30)
#ax15 = fig2.add_subplot(337)
neg_identifier.hist(alpha=0.5, bins=30)

# Auxiliary
ax16 = fig2.add_subplot(338)
ax16.set_xlabel('Auxiliary')
ax16.set_ylabel('Count')
ax16.set_title('Auxiliary query Distribution')
pos_Auxiliary.hist(alpha=0.5, bins=30)
#ax17 = fig2.add_subplot(338)
neg_Auxiliary.hist(alpha=0.5, bins=30)

# Location
ax18 = fig2.add_subplot(339)
ax18.set_xlabel('Location')
ax18.set_ylabel('Count')
ax18.set_title('Location query Distribution')
pos_Location.hist(alpha=0.5, bins=30)
#ax19 = fig2.add_subplot(339)
neg_Location.hist(alpha=0.5, bins=30)


c = DecisionTreeClassifier(min_samples_split = 100) # the goal is to split observations into groups of homogeneous

features = ["Command", "Punctuations","Comparison", "Comments", "Logical Operators", "Literal","Identifier", "Auxiliary", "Location"]
x_train = train[features]
y_train = train["Malicious"]

x_test = test[features]
y_test = test["Malicious"]

dt = c.fit(x_train, y_train)
#this function displays the tree
def display_tree(tree, features, path):
    f= io.StringIO()
    export_graphviz(tree, out_file=f, feature_names=features)
    pydotplus.graph_from_dot_data(f.getvalue()).write_png(path)
    img = imageio.imread(path)
    plt.rcParams["figure.figsize"] = (30, 40)
    plt.imshow(img)  
    
    display_tree(dt, features, 'dec_tree.png')
    y_pred = c.predict(x_test)
    y_pred
    from sklearn.metrics import accuracy_score
score = accuracy_score(y_test, y_pred) * 100
print("The accuracy of using Decision Tree Classifier is: ", round(score, 1),"%")
